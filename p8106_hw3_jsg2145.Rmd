---
title: "p8106_hw3_jsg2145"
author: "Jared Garfinkel"
date: "4/14/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(ISLR)
library(caret)
library(AppliedPredictiveModeling)
library(pROC)
library(MASS)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r, cache = TRUE}
data("Weekly")

df = Weekly %>% 
  janitor::clean_names()
```

## Part a

```{r}
theme1 <- transparentTheme(trans = .4)
theme1$strip.background$col <- rgb(.0, .6, .2, .2) 
trellis.par.set(theme1)

featurePlot(x = df[, 1:8], 
            y = df$direction,
            scales = list(x=list(relation="free"), 
                          y=list(relation="free")),
            plot = "density", pch = "|", 
            auto.key = list(columns = 2))
```

## Part b

```{r, cache = TRUE}
df_glm <- glm(direction ~ lag1 + lag2 + lag3 + lag4 + lag5 + volume, 
              data=df, 
              family="binomial")
summary(df_glm)
```

Only the lag2 predictor appears significant at p = `r df_glm %>% broom::tidy() %>% filter(term == "lag2") %>% pull(p.value) %>% round(4)` < 0.05.

## Part c

```{r}
df_pred = predict(df_glm, type = "response")
df_test_pred = rep("Down", length(df_pred))
df_test_pred[df_pred > 0.5] = "Up"
df_confusion = confusionMatrix(data = as.factor(df_test_pred),
                               reference = df$direction,
                               positive = "Up")
```

The sensitivity is `r df_confusion %>% broom::tidy() %>% filter(term == "sensitivity") %>% pull(estimate) %>% round(4)`, indicating a high degree of true positives, while the specificity is `r df_confusion %>% broom::tidy() %>% filter(term == "specificity") %>% pull(estimate) %>% round(4)`, indicating that when the market goes down, there are less than 12% of true negatives. Kappa is `r df_confusion %>% broom::tidy() %>% filter(term == "kappa") %>% pull(estimate) %>% round(4)`, a measure of the agreement between the predictive value and true value.

## Part d

```{r}
df_roc <- roc(df$direction, df_pred) 
plot(df_roc, legacy.axes = TRUE, print.auc = TRUE) 
plot(smooth(df_roc), col = 4, add = TRUE)
```

The AUC is `r df_roc$auc %>% round(4)`.

```{r}
df_train = df %>% 
  filter(year < 2009)

df_test = df %>% 
  filter(year > 2008)
```

```{r}
df_glm_train <- glm(direction ~ lag1 + lag2, data = df_train, family = "binomial")
df_glm_test <- predict(df_glm_train, type = "response", newdata = df_test)
df_roc_split <- roc(df_test$direction, df_glm_test)
plot(df_roc_split, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(df_roc_split), col = 4, add = TRUE)
```

The AUC is `r df_roc_split$auc %>% round(4)`.

## Part f

```{r}
df_lda = lda(direction ~ lag1 + lag2, data = df_train)
df_lda
plot(df_lda)

df_lda_pred <- predict(df_lda, newdata = df_test)

df_roc_lda <- roc(df_test$direction, df_lda_pred$posterior[,2])
plot(df_roc_lda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(df_roc_lda), col = 4, add = TRUE)
```

The AUC is `r df_roc_lda$auc %>% round(4)`.

```{r}
df_qda <- qda(direction ~ lag1 + lag2, data = df_train)
df_qda_pred <- predict(df_qda, newdata = df_test)

df_roc_qda <- roc(df_test$direction, df_qda_pred$posterior[,2], 
               levels = c("Down", "Up"))
plot(df_roc_qda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(df_roc_qda), col = 4, add = TRUE)
```

The AUC is `r df_roc_qda$auc %>% round(4)`.

```{r}
ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5)

df_knn = train(x = df_train[2:3],
                y = df_train$direction,
                method = "knn",
                preProcess = c("center","scale"),
                tuneGrid = data.frame(k = seq(1, 200, by = 5)),
                trControl = ctrl1)

ggplot(df_knn)

df_knn_pred = predict(df_knn, newdata = df_test, type = "prob")[,2]
df_roc_knn = roc(df_test$direction, df_knn_pred)
plot(df_roc_knn, legacy.axes = TRUE, print.auc = TRUE)

```

The AUC for KNN is `r df_roc_knn$auc %>% round(4)`. This is relatively higher than the other AUC's.
